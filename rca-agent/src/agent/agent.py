# Copyright 2025 The OpenChoreo Authors
# SPDX-License-Identifier: Apache-2.0

import asyncio
import json
import logging
import uuid
from collections.abc import AsyncIterator
from typing import Any
from uuid import UUID

import httpx
from langchain.agents import create_agent
from langchain.agents.middleware import SummarizationMiddleware, TodoListMiddleware
from langchain.agents.structured_output import ProviderStrategy, StructuredOutputValidationError
from langchain_core.callbacks import BaseCallbackHandler, UsageMetadataCallbackHandler
from langchain_core.runnables import Runnable, RunnableConfig
from pydantic import BaseModel

from src.agent.helpers import AlertScope, resolve_component_scope
from src.agent.middleware import (
    LoggingMiddleware,
    OutputTransformerMiddleware,
    ToolErrorHandlerMiddleware,
)
from src.agent.stream_parser import ChatResponseParser
from src.agent.tool_registry import OBSERVABILITY_TOOLS, OPENCHOREO_TOOLS, TOOL_ACTIVE_FORMS, TOOLS
from src.auth.bearer import BearerTokenAuth
from src.auth.oauth_client import get_oauth2_auth
from src.clients import MCPClient, ReportBackend, get_model, get_report_backend
from src.config import settings
from src.logging_config import request_id_context
from src.models import ChatResponse, RCAReport
from src.models.rca_report import RootCauseIdentified
from src.models.remediation_result import RemediationResult
from src.template_manager import render

logger = logging.getLogger(__name__)


class Agent:
    def __init__(
        self,
        *,
        template: str,
        tools: set[str],
        middleware: list[type],
        response_format: type[BaseModel],
        recursion_limit: int,
        use_summarization: bool = False,
    ):
        self.template = template
        self.tools = tools
        self.response_format = response_format
        self.recursion_limit = recursion_limit
        self.model = get_model()
        self._middleware_classes = middleware
        self._use_summarization = use_summarization

    async def create(
        self,
        auth: httpx.Auth,
        usage_callback: BaseCallbackHandler | None = None,
        context: dict[str, Any] | None = None,
    ) -> Runnable:
        mcp_client = MCPClient(auth=auth)
        all_tools = await mcp_client.get_tools()
        tools = [t for t in all_tools if t.name in self.tools]
        logger.debug("Filtered to %d tools: %s", len(tools), [t.name for t in tools])

        template_context = {
            "tools": tools,
            "observability_tools": [t for t in tools if t.name in OBSERVABILITY_TOOLS],
            "openchoreo_tools": [t for t in tools if t.name in OPENCHOREO_TOOLS],
        }
        if context:
            template_context.update(context)

        middleware = [m() for m in self._middleware_classes]
        if self._use_summarization:
            middleware.append(SummarizationMiddleware(model=self.model, trigger=("fraction", 0.8)))

        agent = create_agent(
            model=self.model,
            tools=tools,
            system_prompt=render(self.template, template_context),
            middleware=middleware,
            response_format=ProviderStrategy(self.response_format),
        )

        runnable_config: RunnableConfig = {"recursion_limit": self.recursion_limit}
        if usage_callback is not None:
            runnable_config["callbacks"] = [usage_callback]

        logger.info("Created agent with %d tools: %s", len(tools), [t.name for t in tools])
        return agent.with_config(runnable_config)


RCA_AGENT = Agent(
    template="prompts/rca_agent_prompt.j2",
    tools={
        TOOLS.GET_TRACES,
        TOOLS.GET_PROJECT_LOGS,
        TOOLS.GET_COMPONENT_LOGS,
        TOOLS.GET_COMPONENT_RESOURCE_METRICS,
        # TOOLS.LIST_PROJECTS,
        TOOLS.LIST_COMPONENTS,
    },
    middleware=[
        LoggingMiddleware,
        ToolErrorHandlerMiddleware,
        OutputTransformerMiddleware,
        TodoListMiddleware,
    ],
    response_format=RCAReport,
    recursion_limit=200,
    use_summarization=True,
)

REMED_AGENT = Agent(
    template="prompts/remed_agent_prompt.j2",
    tools={
        TOOLS.LIST_COMPONENTS,
        TOOLS.LIST_RELEASE_BINDINGS,
        TOOLS.GET_COMPONENT_RELEASE_SCHEMA,
        TOOLS.GET_COMPONENT_WORKLOADS,
        TOOLS.LIST_COMPONENT_TRAITS,
    },
    middleware=[
        LoggingMiddleware,
        ToolErrorHandlerMiddleware,
    ],
    response_format=RemediationResult,
    recursion_limit=50,
)

CHAT_AGENT = Agent(
    template="prompts/chat_agent_prompt.j2",
    tools={
        TOOLS.GET_TRACES,
        TOOLS.GET_PROJECT_LOGS,
        TOOLS.GET_COMPONENT_LOGS,
        TOOLS.GET_COMPONENT_RESOURCE_METRICS,
        # TOOLS.LIST_PROJECTS,
        TOOLS.LIST_COMPONENTS,
    },
    middleware=[
        LoggingMiddleware,
        ToolErrorHandlerMiddleware,
        OutputTransformerMiddleware,
    ],
    response_format=ChatResponse,
    recursion_limit=50,
    use_summarization=True,
)


# Module-level semaphore for limiting concurrent analyses
_semaphore: asyncio.Semaphore | None = None


def _get_semaphore() -> asyncio.Semaphore:
    global _semaphore
    if _semaphore is None:
        _semaphore = asyncio.Semaphore(settings.max_concurrent_analyses)
    return _semaphore


async def stream_chat(
    messages: list[dict[str, str]],
    token: str,
    report_context: dict[str, Any] | None = None,
    scope: AlertScope | None = None,
) -> AsyncIterator[str]:
    request_id_context.set(f"msg_{uuid.uuid4().hex[:12]}")

    def emit(event: dict[str, Any]) -> str:
        return json.dumps(event) + "\n"  # Newline for ndjson

    try:
        agent = await CHAT_AGENT.create(
            auth=BearerTokenAuth(token),
            context={"scope": scope, "report_context": report_context},
        )

        agent_messages = list(messages)

        parser = ChatResponseParser()

        try:
            async for chunk, _ in agent.astream(
                {"messages": agent_messages},
                stream_mode="messages",
            ):
                # Skip non-AI message chunks (e.g., ToolMessage has content as list)
                if not isinstance(chunk.content, str):
                    continue

                for block in chunk.content_blocks:
                    block_type = block.get("type")

                    if block_type == "tool_call_chunk":
                        tool_name = block.get("name")
                        args = block.get("args", "")
                        if tool_name:
                            active_form = TOOL_ACTIVE_FORMS.get(tool_name)
                            yield emit(
                                {
                                    "type": "tool_call",
                                    "tool": tool_name,
                                    "activeForm": active_form,
                                    "args": args,
                                }
                            )

                    elif block_type == "text":
                        text = block.get("text", "")
                        if text:
                            delta = parser.push(text)
                            if delta:
                                yield emit({"type": "message_chunk", "content": delta})
        except StructuredOutputValidationError:
            logger.warning("Structured output validation failed, using streamed content")

        # Emit actions event if actions exist
        if parser.actions:
            yield emit({"type": "actions", "actions": parser.actions})

        # Build done event with parsed response
        yield emit({"type": "done", "message": parser.message})

    except Exception as e:
        logger.error("Chat stream error: %s", e, exc_info=True)
        yield emit(
            {
                "type": "error",
                "message": f"An error occured (request_id: {request_id_context.get()})",
            }
        )


async def run_analysis(
    report_id: str,
    alert_id: str,
    alert: Any,
    component_uid: UUID,
    project_uid: UUID,
    environment_uid: UUID,
    meta: dict[str, Any] | None = None,
) -> None:
    # Set request_id in context for logging (use report_id as it's unique per request)
    request_id_context.set(report_id)

    semaphore = _get_semaphore()
    report_backend = get_report_backend()

    logger.info("Analysis task queued")

    async with semaphore:
        logger.info("Analysis task started")

        try:
            usage_callback = UsageMetadataCallbackHandler()

            rca_agent = await RCA_AGENT.create(
                auth=get_oauth2_auth(), usage_callback=usage_callback
            )

            ## TODO: Remove once namespace/environment info is received from upstream
            scope = await resolve_component_scope(component_uid, environment_uid)

            content = render(
                "api/rca_request.j2",
                {"alert": alert, "meta": meta, "scope": scope},
            )

            rca_result = await asyncio.wait_for(
                rca_agent.ainvoke(
                    {
                        "messages": [
                            {
                                "role": "user",
                                "content": content,
                            }
                        ],
                    }
                ),
                timeout=settings.analysis_timeout_seconds,
            )

            rca_report: RCAReport = rca_result["structured_response"]
            logger.info("RCA completed: usage=%s", usage_callback.usage_metadata)

            report_data = rca_report.model_dump()

            if settings.remed_agent and isinstance(rca_report.result, RootCauseIdentified):
                try:
                    logger.info("Running remediation agent")
                    remed_agent = await REMED_AGENT.create(
                        auth=get_oauth2_auth(),
                        usage_callback=usage_callback,
                        context={"scope": scope},
                    )

                    remed_result = await asyncio.wait_for(
                        remed_agent.ainvoke(
                            {
                                "messages": [
                                    {
                                        "role": "user",
                                        "content": rca_report.model_dump_json(
                                            exclude={
                                                "result": {
                                                    "recommendations": {
                                                        "observability_recommendations"
                                                    }
                                                }
                                            }
                                        ),
                                    }
                                ],
                            }
                        ),
                        timeout=settings.analysis_timeout_seconds,
                    )

                    remed_report: RemediationResult = remed_result["structured_response"]
                    report_data["result"]["recommendations"]["recommended_actions"] = [
                        a.model_dump() for a in remed_report.recommended_actions
                    ]
                    logger.info("Remediation completed: usage=%s", usage_callback.usage_metadata)
                except Exception as e:
                    logger.error("Remediation agent failed, saving RCA report without it: %s", e)

            response = await report_backend.upsert_rca_report(
                report_id=report_id,
                alert_id=alert_id,
                status="completed",
                report=report_data,
                environment_uid=str(environment_uid),
                project_uid=str(project_uid),
                component_uids=[str(component_uid)],
            )
            logger.info(
                "Updated RCA report to completed: index=%s, status=%s",
                response.get("_index"),
                response.get("result"),
            )

        except TimeoutError:
            logger.error(
                "Analysis timed out after %d seconds",
                settings.analysis_timeout_seconds,
            )
            await _update_failed_status(
                report_backend,
                report_id,
                alert_id,
                environment_uid,
                project_uid,
                component_uid,
                f"Analysis timed out (report_id: {report_id})",
            )

        except Exception as e:
            logger.error("Analysis failed: error=%s", e, exc_info=True)
            await _update_failed_status(
                report_backend,
                report_id,
                alert_id,
                environment_uid,
                project_uid,
                component_uid,
                f"Analysis failed (report_id: {report_id})",
            )


async def _update_failed_status(
    report_backend: ReportBackend,
    report_id: str,
    alert_id: str,
    environment_uid: UUID,
    project_uid: UUID,
    component_uid: UUID,
    summary: str,
) -> None:
    try:
        await report_backend.upsert_rca_report(
            report_id=report_id,
            alert_id=alert_id,
            status="failed",
            summary=summary,
            environment_uid=str(environment_uid),
            project_uid=str(project_uid),
            component_uids=[str(component_uid)],
        )
        logger.info("Updated RCA report status to failed")
    except Exception as update_error:
        logger.error(
            "Failed to update failed status to OpenSearch: error=%s",
            update_error,
            exc_info=True,
        )
